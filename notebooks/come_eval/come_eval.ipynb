{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from IPython.core.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sortedcontainers import SortedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from  matplotlib.ticker import PercentFormatter\n",
    "import utils.graph_utils as graph_utils\n",
    "from utils.IO_utils import load_ground_true\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [],
   "source": [
    "# settings\n",
    "np.random.seed(2020)\n",
    "name = \"Dblp\"\n",
    "d = 128\n",
    "come_model_type = \"BGMM\"\n",
    "ks = [2, 5, 10, 20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [],
   "source": [
    "# import graph and true labels\n",
    "\n",
    "# graph\n",
    "G = graph_utils.load_matfile(f\"../../data/{name}/{name}.mat\", undirected=True)\n",
    "\n",
    "# labels_true\n",
    "labels_true, _ = load_ground_true(path=f\"../../data/{name}\", file_name=name)\n",
    "labels_true = np.array(labels_true) - 1  # 1..5 -> 0..4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anton/miniconda3/envs/MT/lib/python3.6/site-packages/ipykernel_launcher.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/Users/anton/miniconda3/envs/MT/lib/python3.6/site-packages/ipykernel_launcher.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": "              1         2         3         4         5         6         7  \\\nnode                                                                          \n0      0.447244 -0.590060 -0.327605  0.759601  0.407560  0.058691  0.100031   \n1      0.295918 -0.558974 -0.200630  0.670498  0.255454  0.012444  0.046877   \n2      0.533605 -0.535543 -0.390154  0.778972  0.445067  0.030342  0.050596   \n3      0.422736 -0.478823 -0.391336  0.637420  0.339128 -0.047656  0.112250   \n4      0.325676 -0.428440 -0.432361  0.703664  0.361787  0.000723 -0.070736   \n...         ...       ...       ...       ...       ...       ...       ...   \n13179  0.257980 -0.395774 -0.185478  0.552952  0.410871 -0.034553 -0.067511   \n13180 -0.020099 -0.540597 -0.269626  0.003425  0.431760  0.091559  0.119777   \n13181 -0.118595 -0.484969 -0.095687  0.009911  0.409799 -0.006928  0.062702   \n13182 -0.079081 -0.163665  0.329716  0.616806  0.285795 -0.213358  0.433964   \n13183 -0.150570 -0.100694 -0.298957  0.520190  0.341279 -0.023270  0.126024   \n\n              8         9        10  ...       121       122       123  \\\nnode                                 ...                                 \n0      0.519430  0.105071  0.309200  ...  0.026815 -0.170982 -0.574228   \n1      0.438116 -0.062488  0.382698  ... -0.077961 -0.241738 -0.520454   \n2      0.546266  0.181827  0.356746  ...  0.023890 -0.090602 -0.596374   \n3      0.464919  0.160469  0.317239  ... -0.017747 -0.144513 -0.465714   \n4      0.472260  0.272814  0.312631  ...  0.039992 -0.145147 -0.551694   \n...         ...       ...       ...  ...       ...       ...       ...   \n13179  0.413107  0.183474  0.325979  ... -0.171239 -0.060339 -0.347124   \n13180  0.100602  0.358634  0.445394  ... -0.318657  0.178803 -0.034317   \n13181  0.008954  0.505634  0.593392  ... -0.070694  0.259097 -0.084647   \n13182  0.407094  0.309780  0.164280  ... -0.174937  0.108733 -0.225076   \n13183  0.471296  0.049665  0.342407  ...  0.077317  0.175741 -0.417408   \n\n            124       125       126       127       128  label_pred  \\\nnode                                                                  \n0     -0.198281 -0.451050  0.011072 -0.094810 -0.301875           1   \n1     -0.098120 -0.499365 -0.048436  0.035603 -0.250949           1   \n2     -0.249288 -0.443732 -0.064824 -0.046458 -0.358123           1   \n3     -0.285970 -0.305572  0.000968 -0.058966 -0.357066           1   \n4     -0.296413 -0.290567 -0.063562 -0.169452 -0.348867           1   \n...         ...       ...       ...       ...       ...         ...   \n13179 -0.287109 -0.128301  0.030241  0.094815 -0.255052           1   \n13180  0.113252  0.093031 -0.522664  0.109797  0.340559           0   \n13181  0.026951 -0.060800 -0.500006  0.138947  0.363550           0   \n13182  0.090487  0.103506 -0.016391  0.368730  0.176136           0   \n13183 -0.164322  0.160704  0.148218 -0.103669 -0.158685           1   \n\n       label_true  \nnode               \n0               0  \n1               2  \n2               2  \n3               0  \n4               0  \n...           ...  \n13179           0  \n13180           3  \n13181           3  \n13182           4  \n13183           0  \n\n[13184 rows x 130 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>121</th>\n      <th>122</th>\n      <th>123</th>\n      <th>124</th>\n      <th>125</th>\n      <th>126</th>\n      <th>127</th>\n      <th>128</th>\n      <th>label_pred</th>\n      <th>label_true</th>\n    </tr>\n    <tr>\n      <th>node</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.447244</td>\n      <td>-0.590060</td>\n      <td>-0.327605</td>\n      <td>0.759601</td>\n      <td>0.407560</td>\n      <td>0.058691</td>\n      <td>0.100031</td>\n      <td>0.519430</td>\n      <td>0.105071</td>\n      <td>0.309200</td>\n      <td>...</td>\n      <td>0.026815</td>\n      <td>-0.170982</td>\n      <td>-0.574228</td>\n      <td>-0.198281</td>\n      <td>-0.451050</td>\n      <td>0.011072</td>\n      <td>-0.094810</td>\n      <td>-0.301875</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.295918</td>\n      <td>-0.558974</td>\n      <td>-0.200630</td>\n      <td>0.670498</td>\n      <td>0.255454</td>\n      <td>0.012444</td>\n      <td>0.046877</td>\n      <td>0.438116</td>\n      <td>-0.062488</td>\n      <td>0.382698</td>\n      <td>...</td>\n      <td>-0.077961</td>\n      <td>-0.241738</td>\n      <td>-0.520454</td>\n      <td>-0.098120</td>\n      <td>-0.499365</td>\n      <td>-0.048436</td>\n      <td>0.035603</td>\n      <td>-0.250949</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.533605</td>\n      <td>-0.535543</td>\n      <td>-0.390154</td>\n      <td>0.778972</td>\n      <td>0.445067</td>\n      <td>0.030342</td>\n      <td>0.050596</td>\n      <td>0.546266</td>\n      <td>0.181827</td>\n      <td>0.356746</td>\n      <td>...</td>\n      <td>0.023890</td>\n      <td>-0.090602</td>\n      <td>-0.596374</td>\n      <td>-0.249288</td>\n      <td>-0.443732</td>\n      <td>-0.064824</td>\n      <td>-0.046458</td>\n      <td>-0.358123</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.422736</td>\n      <td>-0.478823</td>\n      <td>-0.391336</td>\n      <td>0.637420</td>\n      <td>0.339128</td>\n      <td>-0.047656</td>\n      <td>0.112250</td>\n      <td>0.464919</td>\n      <td>0.160469</td>\n      <td>0.317239</td>\n      <td>...</td>\n      <td>-0.017747</td>\n      <td>-0.144513</td>\n      <td>-0.465714</td>\n      <td>-0.285970</td>\n      <td>-0.305572</td>\n      <td>0.000968</td>\n      <td>-0.058966</td>\n      <td>-0.357066</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.325676</td>\n      <td>-0.428440</td>\n      <td>-0.432361</td>\n      <td>0.703664</td>\n      <td>0.361787</td>\n      <td>0.000723</td>\n      <td>-0.070736</td>\n      <td>0.472260</td>\n      <td>0.272814</td>\n      <td>0.312631</td>\n      <td>...</td>\n      <td>0.039992</td>\n      <td>-0.145147</td>\n      <td>-0.551694</td>\n      <td>-0.296413</td>\n      <td>-0.290567</td>\n      <td>-0.063562</td>\n      <td>-0.169452</td>\n      <td>-0.348867</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13179</th>\n      <td>0.257980</td>\n      <td>-0.395774</td>\n      <td>-0.185478</td>\n      <td>0.552952</td>\n      <td>0.410871</td>\n      <td>-0.034553</td>\n      <td>-0.067511</td>\n      <td>0.413107</td>\n      <td>0.183474</td>\n      <td>0.325979</td>\n      <td>...</td>\n      <td>-0.171239</td>\n      <td>-0.060339</td>\n      <td>-0.347124</td>\n      <td>-0.287109</td>\n      <td>-0.128301</td>\n      <td>0.030241</td>\n      <td>0.094815</td>\n      <td>-0.255052</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13180</th>\n      <td>-0.020099</td>\n      <td>-0.540597</td>\n      <td>-0.269626</td>\n      <td>0.003425</td>\n      <td>0.431760</td>\n      <td>0.091559</td>\n      <td>0.119777</td>\n      <td>0.100602</td>\n      <td>0.358634</td>\n      <td>0.445394</td>\n      <td>...</td>\n      <td>-0.318657</td>\n      <td>0.178803</td>\n      <td>-0.034317</td>\n      <td>0.113252</td>\n      <td>0.093031</td>\n      <td>-0.522664</td>\n      <td>0.109797</td>\n      <td>0.340559</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>13181</th>\n      <td>-0.118595</td>\n      <td>-0.484969</td>\n      <td>-0.095687</td>\n      <td>0.009911</td>\n      <td>0.409799</td>\n      <td>-0.006928</td>\n      <td>0.062702</td>\n      <td>0.008954</td>\n      <td>0.505634</td>\n      <td>0.593392</td>\n      <td>...</td>\n      <td>-0.070694</td>\n      <td>0.259097</td>\n      <td>-0.084647</td>\n      <td>0.026951</td>\n      <td>-0.060800</td>\n      <td>-0.500006</td>\n      <td>0.138947</td>\n      <td>0.363550</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>13182</th>\n      <td>-0.079081</td>\n      <td>-0.163665</td>\n      <td>0.329716</td>\n      <td>0.616806</td>\n      <td>0.285795</td>\n      <td>-0.213358</td>\n      <td>0.433964</td>\n      <td>0.407094</td>\n      <td>0.309780</td>\n      <td>0.164280</td>\n      <td>...</td>\n      <td>-0.174937</td>\n      <td>0.108733</td>\n      <td>-0.225076</td>\n      <td>0.090487</td>\n      <td>0.103506</td>\n      <td>-0.016391</td>\n      <td>0.368730</td>\n      <td>0.176136</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>13183</th>\n      <td>-0.150570</td>\n      <td>-0.100694</td>\n      <td>-0.298957</td>\n      <td>0.520190</td>\n      <td>0.341279</td>\n      <td>-0.023270</td>\n      <td>0.126024</td>\n      <td>0.471296</td>\n      <td>0.049665</td>\n      <td>0.342407</td>\n      <td>...</td>\n      <td>0.077317</td>\n      <td>0.175741</td>\n      <td>-0.417408</td>\n      <td>-0.164322</td>\n      <td>0.160704</td>\n      <td>0.148218</td>\n      <td>-0.103669</td>\n      <td>-0.158685</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>13184 rows × 130 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                  1             2             3             4             5  \\\ncount  13184.000000  13184.000000  13184.000000  13184.000000  13184.000000   \nmean       0.070362     -0.349749     -0.039339      0.317448      0.314261   \nstd        0.158703      0.187695      0.180287      0.210781      0.165113   \nmin       -0.508291     -1.023050     -0.624764     -0.434922     -0.292775   \n25%       -0.032193     -0.487592     -0.161421      0.168124      0.208116   \n50%        0.071219     -0.348648     -0.047358      0.329033      0.321037   \n75%        0.174777     -0.212791      0.073073      0.479097      0.422816   \nmax        0.637020      0.296944      0.650146      0.993297      0.928177   \n\n                  6             7             8             9            10  \\\ncount  13184.000000  13184.000000  13184.000000  13184.000000  13184.000000   \nmean      -0.113492      0.198119      0.249685      0.185212      0.415116   \nstd        0.194175      0.185949      0.172968      0.186557      0.152076   \nmin       -0.728536     -0.466597     -0.464700     -0.451996     -0.187440   \n25%       -0.263246      0.068560      0.132015      0.043462      0.317043   \n50%       -0.114689      0.197320      0.254364      0.171024      0.419377   \n75%        0.028225      0.326423      0.364569      0.318899      0.515942   \nmax        0.465188      0.867931      0.845109      0.869033      0.919915   \n\n       ...           121           122           123           124  \\\ncount  ...  13184.000000  13184.000000  13184.000000  13184.000000   \nmean   ...     -0.116847      0.216113     -0.288452     -0.003144   \nstd    ...      0.149657      0.157409      0.220734      0.148219   \nmin    ...     -0.741044     -0.457601     -0.949299     -0.708024   \n25%    ...     -0.216404      0.111103     -0.451154     -0.091365   \n50%    ...     -0.114634      0.219112     -0.293272     -0.000578   \n75%    ...     -0.016848      0.319095     -0.113045      0.089160   \nmax    ...      0.413959      0.770119      0.419585      0.654550   \n\n                125           126           127           128    label_pred  \\\ncount  13184.000000  13184.000000  13184.000000  13184.000000  13184.000000   \nmean      -0.033984     -0.015064      0.099052      0.109553      0.386074   \nstd        0.179455      0.163438      0.173225      0.249231      0.486866   \nmin       -0.760009     -0.728847     -0.512301     -0.561539      0.000000   \n25%       -0.161933     -0.116730     -0.018078     -0.096275      0.000000   \n50%       -0.035395     -0.010756      0.092400      0.131962      0.000000   \n75%        0.090639      0.094135      0.211754      0.305395      1.000000   \nmax        0.548400      0.575931      0.699623      0.888070      1.000000   \n\n         label_true  \ncount  13184.000000  \nmean       2.190382  \nstd        1.315339  \nmin        0.000000  \n25%        1.000000  \n50%        3.000000  \n75%        3.000000  \nmax        4.000000  \n\n[8 rows x 130 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>121</th>\n      <th>122</th>\n      <th>123</th>\n      <th>124</th>\n      <th>125</th>\n      <th>126</th>\n      <th>127</th>\n      <th>128</th>\n      <th>label_pred</th>\n      <th>label_true</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>...</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.070362</td>\n      <td>-0.349749</td>\n      <td>-0.039339</td>\n      <td>0.317448</td>\n      <td>0.314261</td>\n      <td>-0.113492</td>\n      <td>0.198119</td>\n      <td>0.249685</td>\n      <td>0.185212</td>\n      <td>0.415116</td>\n      <td>...</td>\n      <td>-0.116847</td>\n      <td>0.216113</td>\n      <td>-0.288452</td>\n      <td>-0.003144</td>\n      <td>-0.033984</td>\n      <td>-0.015064</td>\n      <td>0.099052</td>\n      <td>0.109553</td>\n      <td>0.386074</td>\n      <td>2.190382</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.158703</td>\n      <td>0.187695</td>\n      <td>0.180287</td>\n      <td>0.210781</td>\n      <td>0.165113</td>\n      <td>0.194175</td>\n      <td>0.185949</td>\n      <td>0.172968</td>\n      <td>0.186557</td>\n      <td>0.152076</td>\n      <td>...</td>\n      <td>0.149657</td>\n      <td>0.157409</td>\n      <td>0.220734</td>\n      <td>0.148219</td>\n      <td>0.179455</td>\n      <td>0.163438</td>\n      <td>0.173225</td>\n      <td>0.249231</td>\n      <td>0.486866</td>\n      <td>1.315339</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-0.508291</td>\n      <td>-1.023050</td>\n      <td>-0.624764</td>\n      <td>-0.434922</td>\n      <td>-0.292775</td>\n      <td>-0.728536</td>\n      <td>-0.466597</td>\n      <td>-0.464700</td>\n      <td>-0.451996</td>\n      <td>-0.187440</td>\n      <td>...</td>\n      <td>-0.741044</td>\n      <td>-0.457601</td>\n      <td>-0.949299</td>\n      <td>-0.708024</td>\n      <td>-0.760009</td>\n      <td>-0.728847</td>\n      <td>-0.512301</td>\n      <td>-0.561539</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-0.032193</td>\n      <td>-0.487592</td>\n      <td>-0.161421</td>\n      <td>0.168124</td>\n      <td>0.208116</td>\n      <td>-0.263246</td>\n      <td>0.068560</td>\n      <td>0.132015</td>\n      <td>0.043462</td>\n      <td>0.317043</td>\n      <td>...</td>\n      <td>-0.216404</td>\n      <td>0.111103</td>\n      <td>-0.451154</td>\n      <td>-0.091365</td>\n      <td>-0.161933</td>\n      <td>-0.116730</td>\n      <td>-0.018078</td>\n      <td>-0.096275</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.071219</td>\n      <td>-0.348648</td>\n      <td>-0.047358</td>\n      <td>0.329033</td>\n      <td>0.321037</td>\n      <td>-0.114689</td>\n      <td>0.197320</td>\n      <td>0.254364</td>\n      <td>0.171024</td>\n      <td>0.419377</td>\n      <td>...</td>\n      <td>-0.114634</td>\n      <td>0.219112</td>\n      <td>-0.293272</td>\n      <td>-0.000578</td>\n      <td>-0.035395</td>\n      <td>-0.010756</td>\n      <td>0.092400</td>\n      <td>0.131962</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.174777</td>\n      <td>-0.212791</td>\n      <td>0.073073</td>\n      <td>0.479097</td>\n      <td>0.422816</td>\n      <td>0.028225</td>\n      <td>0.326423</td>\n      <td>0.364569</td>\n      <td>0.318899</td>\n      <td>0.515942</td>\n      <td>...</td>\n      <td>-0.016848</td>\n      <td>0.319095</td>\n      <td>-0.113045</td>\n      <td>0.089160</td>\n      <td>0.090639</td>\n      <td>0.094135</td>\n      <td>0.211754</td>\n      <td>0.305395</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.637020</td>\n      <td>0.296944</td>\n      <td>0.650146</td>\n      <td>0.993297</td>\n      <td>0.928177</td>\n      <td>0.465188</td>\n      <td>0.867931</td>\n      <td>0.845109</td>\n      <td>0.869033</td>\n      <td>0.919915</td>\n      <td>...</td>\n      <td>0.413959</td>\n      <td>0.770119</td>\n      <td>0.419585</td>\n      <td>0.654550</td>\n      <td>0.548400</td>\n      <td>0.575931</td>\n      <td>0.699623</td>\n      <td>0.888070</td>\n      <td>1.000000</td>\n      <td>4.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 130 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import node embeddings and predicted labels\n",
    "dfs = {}\n",
    "for k in ks:\n",
    "    # import node embeddings\n",
    "    df = pd.read_csv(\n",
    "        f\"./data/{name}_alpha-0.1_beta-0.1_ws-10_neg-5_lr-0.025_icom-219_ind-219_k-{k}_ds-0.0_type-{come_model_type}.txt\",\n",
    "        sep=\"\\t| \",\n",
    "        header=None\n",
    "    )\n",
    "    df = df.rename(columns={0: 'node'})\n",
    "    df.set_index(['node'], inplace=True)\n",
    "\n",
    "    # import predicted labels\n",
    "    labels_pred = pd.read_csv(f\"./data/labels_pred_{come_model_type}_{k}.txt\", header=None)\n",
    "    labels_pred = labels_pred.rename(columns={0: 'label_pred'})\n",
    "    labels_pred.label_pred = labels_pred.astype(int)\n",
    "\n",
    "    # join labels pred and true to embeddings\n",
    "    df = df.join(labels_pred)\n",
    "    df['label_true'] = labels_true\n",
    "\n",
    "    print(f\"k = {k}\")\n",
    "    display(df)\n",
    "    display(df.describe())\n",
    "    dfs[k] = df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Community Detection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# NMI\n",
    "\n",
    "for k in dfs:\n",
    "    print(\"K =\", k)\n",
    "    df = dfs[k]\n",
    "    labels_pred = df.label_pred.to_numpy()\n",
    "    labels_true = df.label_true.to_numpy()\n",
    "\n",
    "    nmi = metrics.normalized_mutual_info_score(labels_true, labels_pred)\n",
    "    print(\"NMI: \", nmi)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Conductance\n",
    "\n",
    "for k in dfs:\n",
    "    print(\"K =\", k)\n",
    "    df = dfs[k]\n",
    "    conductance_min = 1\n",
    "    for i in range(k):\n",
    "        nodes = df[df.label_pred == i].index.to_numpy()\n",
    "        conductance_i = nx.conductance(G, nodes)\n",
    "        print(f\"  i{i} conductance: {conductance_i}\")\n",
    "        conductance_min = min(conductance_min, conductance_i)\n",
    "    print(f\"=>conductance: {conductance_min}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Node Classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train LibSVM classifier on 90% of data and test on 10%.\n",
    "\n",
    "for k in ks:\n",
    "    print(f\"k = {k}\")\n",
    "    df = dfs[k]\n",
    "\n",
    "    # train/test split\n",
    "    train, test = train_test_split(df, test_size=0.1)\n",
    "    feature_col = np.arange(0,128) + 1\n",
    "    X_train = train.loc[:, feature_col]\n",
    "    Y_train = train.label_true\n",
    "    X_test = test.loc[:, feature_col]\n",
    "    Y_test = test.label_true\n",
    "\n",
    "    # fit\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "    # pred\n",
    "    Y_pred = clf.predict(X_test)\n",
    "\n",
    "    # results\n",
    "    micro_f1 = metrics.f1_score(Y_test, Y_pred, average='micro')\n",
    "    macro_f1 = metrics.f1_score(Y_test, Y_pred, average='macro')\n",
    "    print(f\"  micro_f1: {micro_f1*100:.2f}\")\n",
    "    print(f\"  macro_f1: {macro_f1*100:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-97a28330",
   "language": "python",
   "display_name": "PyCharm (ComE_BGMM)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}