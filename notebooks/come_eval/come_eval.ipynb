{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from IPython.core.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import utils.graph_utils as graph_utils\n",
    "from utils.IO_utils import load_ground_true\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# settings\n",
    "np.random.seed(2020)\n",
    "name = \"Dblp\"\n",
    "dim = 128\n",
    "come_model_type = \"GMM\"\n",
    "ks = [20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# import graph and true labels\n",
    "\n",
    "# graph\n",
    "G = graph_utils.load_matfile(f\"../../data/{name}/{name}.mat\", undirected=True)\n",
    "\n",
    "# labels_true\n",
    "labels_true, _ = load_ground_true(path=f\"../../data/{name}\", file_name=name)\n",
    "labels_true = np.array(labels_true) - 1  # 1..5 -> 0..4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anton/miniconda3/envs/MT/lib/python3.6/site-packages/ipykernel_launcher.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 20\n"
     ]
    },
    {
     "data": {
      "text/plain": "              1         2         3         4         5         6         7  \\\nnode                                                                          \n0      0.436527 -0.564456 -0.454166  0.641066  0.168700  0.082310 -0.031954   \n1      0.403277 -0.511639 -0.333275  0.545582  0.051169  0.028561 -0.091227   \n2      0.487985 -0.513284 -0.554191  0.689418  0.271111  0.052279 -0.025626   \n3      0.424656 -0.452077 -0.523225  0.574095  0.080523 -0.010256  0.022688   \n4      0.372900 -0.446677 -0.523795  0.631834  0.126949  0.054397 -0.117205   \n...         ...       ...       ...       ...       ...       ...       ...   \n13179  0.374316 -0.279774 -0.335749  0.397761  0.261890 -0.008758 -0.188682   \n13180  0.054672 -0.411832 -0.357445 -0.168166  0.181663  0.170066 -0.083065   \n13181 -0.020217 -0.474941 -0.114838  0.143250  0.312997 -0.027986 -0.050794   \n13182 -0.028331 -0.063932  0.380725  0.513316  0.252685 -0.286332  0.327488   \n13183 -0.370309 -0.050567 -0.334052  0.653980  0.279628  0.042197  0.153782   \n\n              8         9        10  ...       121       122       123  \\\nnode                                 ...                                 \n0      0.361073 -0.208672  0.276056  ...  0.050538 -0.224988 -0.431624   \n1      0.370079 -0.289292  0.483094  ... -0.015528 -0.363553 -0.475505   \n2      0.387778 -0.092199  0.317105  ... -0.009474 -0.074029 -0.445090   \n3      0.317095 -0.171146  0.266117  ... -0.084191 -0.234062 -0.329075   \n4      0.325753 -0.081025  0.227695  ...  0.068887 -0.225661 -0.478980   \n...         ...       ...       ...  ...       ...       ...       ...   \n13179  0.413393 -0.071640  0.283936  ... -0.216151 -0.344590 -0.358659   \n13180  0.187582  0.377385  0.344669  ... -0.356740  0.299442 -0.133717   \n13181 -0.158910  0.536100  0.444589  ...  0.131581  0.298015 -0.208109   \n13182  0.211173  0.131060  0.189965  ... -0.166345 -0.143492 -0.145777   \n13183  0.435926 -0.176014  0.227848  ...  0.131366  0.214615 -0.300434   \n\n            124       125       126       127       128  label_pred  \\\nnode                                                                  \n0      0.003662 -0.477081  0.121960  0.052909 -0.350542           1   \n1      0.014565 -0.530358 -0.040160  0.263523 -0.140697           1   \n2     -0.088949 -0.461879  0.054054  0.101626 -0.306905           1   \n3     -0.094375 -0.241655  0.048418  0.168131 -0.347555           1   \n4     -0.154673 -0.311928 -0.065331  0.082394 -0.291411           1   \n...         ...       ...       ...       ...       ...         ...   \n13179 -0.285082 -0.202561 -0.054232  0.287505 -0.183615           1   \n13180  0.038592  0.229791 -0.662603  0.141447  0.282151           8   \n13181  0.016640 -0.277913 -0.598272  0.087692  0.395714          10   \n13182 -0.028372 -0.018084  0.097057  0.535662  0.044833           6   \n13183 -0.180724  0.218429  0.116496 -0.050974 -0.149814           1   \n\n       label_true  \nnode               \n0               0  \n1               2  \n2               2  \n3               0  \n4               0  \n...           ...  \n13179           0  \n13180           3  \n13181           3  \n13182           4  \n13183           0  \n\n[13184 rows x 130 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>121</th>\n      <th>122</th>\n      <th>123</th>\n      <th>124</th>\n      <th>125</th>\n      <th>126</th>\n      <th>127</th>\n      <th>128</th>\n      <th>label_pred</th>\n      <th>label_true</th>\n    </tr>\n    <tr>\n      <th>node</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.436527</td>\n      <td>-0.564456</td>\n      <td>-0.454166</td>\n      <td>0.641066</td>\n      <td>0.168700</td>\n      <td>0.082310</td>\n      <td>-0.031954</td>\n      <td>0.361073</td>\n      <td>-0.208672</td>\n      <td>0.276056</td>\n      <td>...</td>\n      <td>0.050538</td>\n      <td>-0.224988</td>\n      <td>-0.431624</td>\n      <td>0.003662</td>\n      <td>-0.477081</td>\n      <td>0.121960</td>\n      <td>0.052909</td>\n      <td>-0.350542</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.403277</td>\n      <td>-0.511639</td>\n      <td>-0.333275</td>\n      <td>0.545582</td>\n      <td>0.051169</td>\n      <td>0.028561</td>\n      <td>-0.091227</td>\n      <td>0.370079</td>\n      <td>-0.289292</td>\n      <td>0.483094</td>\n      <td>...</td>\n      <td>-0.015528</td>\n      <td>-0.363553</td>\n      <td>-0.475505</td>\n      <td>0.014565</td>\n      <td>-0.530358</td>\n      <td>-0.040160</td>\n      <td>0.263523</td>\n      <td>-0.140697</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.487985</td>\n      <td>-0.513284</td>\n      <td>-0.554191</td>\n      <td>0.689418</td>\n      <td>0.271111</td>\n      <td>0.052279</td>\n      <td>-0.025626</td>\n      <td>0.387778</td>\n      <td>-0.092199</td>\n      <td>0.317105</td>\n      <td>...</td>\n      <td>-0.009474</td>\n      <td>-0.074029</td>\n      <td>-0.445090</td>\n      <td>-0.088949</td>\n      <td>-0.461879</td>\n      <td>0.054054</td>\n      <td>0.101626</td>\n      <td>-0.306905</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.424656</td>\n      <td>-0.452077</td>\n      <td>-0.523225</td>\n      <td>0.574095</td>\n      <td>0.080523</td>\n      <td>-0.010256</td>\n      <td>0.022688</td>\n      <td>0.317095</td>\n      <td>-0.171146</td>\n      <td>0.266117</td>\n      <td>...</td>\n      <td>-0.084191</td>\n      <td>-0.234062</td>\n      <td>-0.329075</td>\n      <td>-0.094375</td>\n      <td>-0.241655</td>\n      <td>0.048418</td>\n      <td>0.168131</td>\n      <td>-0.347555</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.372900</td>\n      <td>-0.446677</td>\n      <td>-0.523795</td>\n      <td>0.631834</td>\n      <td>0.126949</td>\n      <td>0.054397</td>\n      <td>-0.117205</td>\n      <td>0.325753</td>\n      <td>-0.081025</td>\n      <td>0.227695</td>\n      <td>...</td>\n      <td>0.068887</td>\n      <td>-0.225661</td>\n      <td>-0.478980</td>\n      <td>-0.154673</td>\n      <td>-0.311928</td>\n      <td>-0.065331</td>\n      <td>0.082394</td>\n      <td>-0.291411</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13179</th>\n      <td>0.374316</td>\n      <td>-0.279774</td>\n      <td>-0.335749</td>\n      <td>0.397761</td>\n      <td>0.261890</td>\n      <td>-0.008758</td>\n      <td>-0.188682</td>\n      <td>0.413393</td>\n      <td>-0.071640</td>\n      <td>0.283936</td>\n      <td>...</td>\n      <td>-0.216151</td>\n      <td>-0.344590</td>\n      <td>-0.358659</td>\n      <td>-0.285082</td>\n      <td>-0.202561</td>\n      <td>-0.054232</td>\n      <td>0.287505</td>\n      <td>-0.183615</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13180</th>\n      <td>0.054672</td>\n      <td>-0.411832</td>\n      <td>-0.357445</td>\n      <td>-0.168166</td>\n      <td>0.181663</td>\n      <td>0.170066</td>\n      <td>-0.083065</td>\n      <td>0.187582</td>\n      <td>0.377385</td>\n      <td>0.344669</td>\n      <td>...</td>\n      <td>-0.356740</td>\n      <td>0.299442</td>\n      <td>-0.133717</td>\n      <td>0.038592</td>\n      <td>0.229791</td>\n      <td>-0.662603</td>\n      <td>0.141447</td>\n      <td>0.282151</td>\n      <td>8</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>13181</th>\n      <td>-0.020217</td>\n      <td>-0.474941</td>\n      <td>-0.114838</td>\n      <td>0.143250</td>\n      <td>0.312997</td>\n      <td>-0.027986</td>\n      <td>-0.050794</td>\n      <td>-0.158910</td>\n      <td>0.536100</td>\n      <td>0.444589</td>\n      <td>...</td>\n      <td>0.131581</td>\n      <td>0.298015</td>\n      <td>-0.208109</td>\n      <td>0.016640</td>\n      <td>-0.277913</td>\n      <td>-0.598272</td>\n      <td>0.087692</td>\n      <td>0.395714</td>\n      <td>10</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>13182</th>\n      <td>-0.028331</td>\n      <td>-0.063932</td>\n      <td>0.380725</td>\n      <td>0.513316</td>\n      <td>0.252685</td>\n      <td>-0.286332</td>\n      <td>0.327488</td>\n      <td>0.211173</td>\n      <td>0.131060</td>\n      <td>0.189965</td>\n      <td>...</td>\n      <td>-0.166345</td>\n      <td>-0.143492</td>\n      <td>-0.145777</td>\n      <td>-0.028372</td>\n      <td>-0.018084</td>\n      <td>0.097057</td>\n      <td>0.535662</td>\n      <td>0.044833</td>\n      <td>6</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>13183</th>\n      <td>-0.370309</td>\n      <td>-0.050567</td>\n      <td>-0.334052</td>\n      <td>0.653980</td>\n      <td>0.279628</td>\n      <td>0.042197</td>\n      <td>0.153782</td>\n      <td>0.435926</td>\n      <td>-0.176014</td>\n      <td>0.227848</td>\n      <td>...</td>\n      <td>0.131366</td>\n      <td>0.214615</td>\n      <td>-0.300434</td>\n      <td>-0.180724</td>\n      <td>0.218429</td>\n      <td>0.116496</td>\n      <td>-0.050974</td>\n      <td>-0.149814</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>13184 rows × 130 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                  1             2             3             4             5  \\\ncount  13184.000000  13184.000000  13184.000000  13184.000000  13184.000000   \nmean       0.000830     -0.270871     -0.011392      0.247383      0.258536   \nstd        0.189273      0.221827      0.219088      0.210020      0.186759   \nmin       -0.760121     -1.043094     -0.790480     -0.482115     -0.385856   \n25%       -0.125075     -0.430068     -0.155517      0.103405      0.134624   \n50%       -0.005971     -0.275395     -0.017926      0.252129      0.252892   \n75%        0.132399     -0.114734      0.127231      0.389884      0.372108   \nmax        0.701677      0.452445      0.678930      1.098140      0.925440   \n\n                  6             7             8             9            10  \\\ncount  13184.000000  13184.000000  13184.000000  13184.000000  13184.000000   \nmean      -0.116252      0.136543      0.129188      0.110883      0.370419   \nstd        0.217118      0.205720      0.212195      0.215034      0.175124   \nmin       -0.820103     -0.522908     -0.544886     -0.563251     -0.230095   \n25%       -0.276165     -0.008557     -0.012369     -0.048370      0.253831   \n50%       -0.121410      0.134579      0.120678      0.090903      0.374856   \n75%        0.028221      0.280896      0.264553      0.252303      0.487054   \nmax        0.663360      0.771111      0.954931      0.978782      1.002611   \n\n       ...           121           122           123           124  \\\ncount  ...  13184.000000  13184.000000  13184.000000  13184.000000   \nmean   ...     -0.133110      0.136703     -0.151722     -0.037213   \nstd    ...      0.177751      0.208749      0.211260      0.179676   \nmin    ...     -0.751202     -0.681993     -0.866390     -0.900184   \n25%    ...     -0.248624     -0.003494     -0.301003     -0.141389   \n50%    ...     -0.129734      0.141454     -0.148097     -0.028531   \n75%    ...     -0.011120      0.280569     -0.007655      0.077459   \nmax    ...      0.470287      0.805955      0.601112      0.714436   \n\n                125           126           127           128    label_pred  \\\ncount  13184.000000  13184.000000  13184.000000  13184.000000  13184.000000   \nmean      -0.070353     -0.016308      0.086585      0.091487      8.838365   \nstd        0.208271      0.186768      0.217748      0.217452      5.582605   \nmin       -0.804824     -0.864746     -0.581872     -0.646253      0.000000   \n25%       -0.221836     -0.136753     -0.066092     -0.063615      4.000000   \n50%       -0.077440     -0.014440      0.067656      0.097432      9.000000   \n75%        0.069192      0.108009      0.215292      0.249464     14.000000   \nmax        0.653253      0.684004      0.912726      0.733946     19.000000   \n\n         label_true  \ncount  13184.000000  \nmean       2.190382  \nstd        1.315339  \nmin        0.000000  \n25%        1.000000  \n50%        3.000000  \n75%        3.000000  \nmax        4.000000  \n\n[8 rows x 130 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>121</th>\n      <th>122</th>\n      <th>123</th>\n      <th>124</th>\n      <th>125</th>\n      <th>126</th>\n      <th>127</th>\n      <th>128</th>\n      <th>label_pred</th>\n      <th>label_true</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>...</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n      <td>13184.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.000830</td>\n      <td>-0.270871</td>\n      <td>-0.011392</td>\n      <td>0.247383</td>\n      <td>0.258536</td>\n      <td>-0.116252</td>\n      <td>0.136543</td>\n      <td>0.129188</td>\n      <td>0.110883</td>\n      <td>0.370419</td>\n      <td>...</td>\n      <td>-0.133110</td>\n      <td>0.136703</td>\n      <td>-0.151722</td>\n      <td>-0.037213</td>\n      <td>-0.070353</td>\n      <td>-0.016308</td>\n      <td>0.086585</td>\n      <td>0.091487</td>\n      <td>8.838365</td>\n      <td>2.190382</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.189273</td>\n      <td>0.221827</td>\n      <td>0.219088</td>\n      <td>0.210020</td>\n      <td>0.186759</td>\n      <td>0.217118</td>\n      <td>0.205720</td>\n      <td>0.212195</td>\n      <td>0.215034</td>\n      <td>0.175124</td>\n      <td>...</td>\n      <td>0.177751</td>\n      <td>0.208749</td>\n      <td>0.211260</td>\n      <td>0.179676</td>\n      <td>0.208271</td>\n      <td>0.186768</td>\n      <td>0.217748</td>\n      <td>0.217452</td>\n      <td>5.582605</td>\n      <td>1.315339</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-0.760121</td>\n      <td>-1.043094</td>\n      <td>-0.790480</td>\n      <td>-0.482115</td>\n      <td>-0.385856</td>\n      <td>-0.820103</td>\n      <td>-0.522908</td>\n      <td>-0.544886</td>\n      <td>-0.563251</td>\n      <td>-0.230095</td>\n      <td>...</td>\n      <td>-0.751202</td>\n      <td>-0.681993</td>\n      <td>-0.866390</td>\n      <td>-0.900184</td>\n      <td>-0.804824</td>\n      <td>-0.864746</td>\n      <td>-0.581872</td>\n      <td>-0.646253</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-0.125075</td>\n      <td>-0.430068</td>\n      <td>-0.155517</td>\n      <td>0.103405</td>\n      <td>0.134624</td>\n      <td>-0.276165</td>\n      <td>-0.008557</td>\n      <td>-0.012369</td>\n      <td>-0.048370</td>\n      <td>0.253831</td>\n      <td>...</td>\n      <td>-0.248624</td>\n      <td>-0.003494</td>\n      <td>-0.301003</td>\n      <td>-0.141389</td>\n      <td>-0.221836</td>\n      <td>-0.136753</td>\n      <td>-0.066092</td>\n      <td>-0.063615</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-0.005971</td>\n      <td>-0.275395</td>\n      <td>-0.017926</td>\n      <td>0.252129</td>\n      <td>0.252892</td>\n      <td>-0.121410</td>\n      <td>0.134579</td>\n      <td>0.120678</td>\n      <td>0.090903</td>\n      <td>0.374856</td>\n      <td>...</td>\n      <td>-0.129734</td>\n      <td>0.141454</td>\n      <td>-0.148097</td>\n      <td>-0.028531</td>\n      <td>-0.077440</td>\n      <td>-0.014440</td>\n      <td>0.067656</td>\n      <td>0.097432</td>\n      <td>9.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.132399</td>\n      <td>-0.114734</td>\n      <td>0.127231</td>\n      <td>0.389884</td>\n      <td>0.372108</td>\n      <td>0.028221</td>\n      <td>0.280896</td>\n      <td>0.264553</td>\n      <td>0.252303</td>\n      <td>0.487054</td>\n      <td>...</td>\n      <td>-0.011120</td>\n      <td>0.280569</td>\n      <td>-0.007655</td>\n      <td>0.077459</td>\n      <td>0.069192</td>\n      <td>0.108009</td>\n      <td>0.215292</td>\n      <td>0.249464</td>\n      <td>14.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.701677</td>\n      <td>0.452445</td>\n      <td>0.678930</td>\n      <td>1.098140</td>\n      <td>0.925440</td>\n      <td>0.663360</td>\n      <td>0.771111</td>\n      <td>0.954931</td>\n      <td>0.978782</td>\n      <td>1.002611</td>\n      <td>...</td>\n      <td>0.470287</td>\n      <td>0.805955</td>\n      <td>0.601112</td>\n      <td>0.714436</td>\n      <td>0.653253</td>\n      <td>0.684004</td>\n      <td>0.912726</td>\n      <td>0.733946</td>\n      <td>19.000000</td>\n      <td>4.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 130 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import node embeddings and predicted labels\n",
    "dfs = {}\n",
    "for k in ks:\n",
    "    # import node embeddings\n",
    "    df = pd.read_csv(\n",
    "        f\"./data/{name}_alpha-0.1_beta-0.1_ws-10_neg-5_lr-0.025_icom-219_ind-219_ds-0.0_d-{dim}_type-{come_model_type}_k-{k}.txt\",\n",
    "        sep=\"\\t| \",\n",
    "        header=None\n",
    "    )\n",
    "    df = df.rename(columns={0: 'node'})\n",
    "    df.set_index(['node'], inplace=True)\n",
    "\n",
    "    # import predicted labels\n",
    "    labels_pred = pd.read_csv(f\"./data/labels_pred_{come_model_type}_d{dim}_k{k}.txt\", header=None)\n",
    "    labels_pred = labels_pred.rename(columns={0: 'label_pred'})\n",
    "    labels_pred.label_pred = labels_pred.astype(int)\n",
    "\n",
    "    # join labels pred and true to embeddings\n",
    "    df = df.join(labels_pred)\n",
    "    df['label_true'] = labels_true\n",
    "\n",
    "    print(f\"k = {k}\")\n",
    "    display(df)\n",
    "    display(df.describe())\n",
    "    dfs[k] = df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Community Detection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 20\n",
      "  i0 conductance: 0.4314936318023929\n",
      "  i1 conductance: 0.28\n",
      "  i2 conductance: 0.4953125\n",
      "  i3 conductance: 0.4541284403669725\n",
      "  i4 conductance: 0.3968934118907338\n",
      "  i5 conductance: 0.5799713876967096\n",
      "  i6 conductance: 0.2177379172894868\n",
      "  i7 conductance: 0.4944215191808039\n",
      "  i8 conductance: 0.275626423690205\n",
      "  i9 conductance: 0.11969825263644061\n",
      "  i10 conductance: 0.4384917943849179\n",
      "  i11 conductance: 0.6968048946295038\n",
      "  i12 conductance: 0.42738950576964946\n",
      "  i13 conductance: 0.5566807313642756\n",
      "  i14 conductance: 0.49779278109581926\n",
      "  i15 conductance: 0.5639548283014519\n",
      "  i16 conductance: 0.44936708860759494\n",
      "  i17 conductance: 0.5272815651962571\n",
      "  i18 conductance: 0.5809213208316347\n",
      "  i19 conductance: 0.5861451179456554\n",
      "=>conductance: 0.11969825263644061\n"
     ]
    }
   ],
   "source": [
    "# Conductance\n",
    "\n",
    "for k in dfs:\n",
    "    print(\"K =\", k)\n",
    "    df = dfs[k]\n",
    "    conductance_min = 1\n",
    "    for i in range(k):\n",
    "        nodes = df[df.label_pred == i].index.to_numpy()\n",
    "        if len(nodes) == 0: continue\n",
    "        conductance_i = nx.conductance(G, nodes)\n",
    "        print(f\"  i{i} conductance: {conductance_i}\")\n",
    "        conductance_min = min(conductance_min, conductance_i)\n",
    "    print(f\"=>conductance: {conductance_min}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 20\n",
      "NMI:  0.3018911505699723\n"
     ]
    }
   ],
   "source": [
    "# NMI\n",
    "\n",
    "for k in dfs:\n",
    "    print(\"K =\", k)\n",
    "    df = dfs[k]\n",
    "    labels_pred = df.label_pred.to_numpy()\n",
    "    labels_true = df.label_true.to_numpy()\n",
    "\n",
    "    nmi = metrics.normalized_mutual_info_score(labels_true, labels_pred)\n",
    "    print(\"NMI: \", nmi)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Node Classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 20\n",
      "  micro_f1: 92.65\n",
      "  macro_f1: 92.66\n"
     ]
    }
   ],
   "source": [
    "# train LibSVM classifier on 90% of data and test on 10%.\n",
    "\n",
    "for k in ks:\n",
    "    print(f\"k = {k}\")\n",
    "    df = dfs[k]\n",
    "\n",
    "    # train/test split\n",
    "    train, test = train_test_split(df, test_size=0.1)\n",
    "    feature_col = np.arange(0, dim) + 1\n",
    "    X_train = train.loc[:, feature_col]\n",
    "    Y_train = train.label_true\n",
    "    X_test = test.loc[:, feature_col]\n",
    "    Y_test = test.label_true\n",
    "\n",
    "    # fit\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "    # pred\n",
    "    Y_pred = clf.predict(X_test)\n",
    "\n",
    "    # results\n",
    "    micro_f1 = metrics.f1_score(Y_test, Y_pred, average='micro')\n",
    "    macro_f1 = metrics.f1_score(Y_test, Y_pred, average='macro')\n",
    "    print(f\"  micro_f1: {micro_f1*100:.2f}\")\n",
    "    print(f\"  macro_f1: {macro_f1*100:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-97a28330",
   "language": "python",
   "display_name": "PyCharm (ComE_BGMM)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}